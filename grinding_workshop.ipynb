{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp-chi\n",
      "Undirected!\n",
      "deezer-europe\n",
      "Undirected!\n",
      "pokec\n",
      "Undirected!\n",
      "arxiv-year\n",
      "Undirected!\n",
      "snap-patents\n",
      "Undirected!\n",
      "chameleon\n",
      "Undirected!\n",
      "cornell\n",
      "Undirected!\n",
      "squirrel\n",
      "Undirected!\n",
      "texas\n",
      "Undirected!\n",
      "wisconsin\n",
      "Undirected!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from utils import load_dataset\n",
    "from model import GCN, ourModel, MLP\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "import torch.nn.functional as F\n",
    "from selecting_algorithm import Flexmatch, UPS\n",
    "import os \n",
    "import pandas as pd \n",
    "import argparse\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import yaml\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "def test(graph):\n",
    "    for i in range(10):\n",
    "        if not torch.sum(graph.edge_index[0]==i) == torch.sum(graph.edge_index[0]==i):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "name_list = [\"yelp-chi\", \"deezer-europe\", \"pokec\", \"arxiv-year\", \"snap-patents\", \"chameleon\", \"cornell\", \"squirrel\", \"texas\", \"wisconsin\"]\n",
    "for name in name_list:\n",
    "    dataset = load_dataset(name)\n",
    "    print(name)\n",
    "    split_dataset_balanced(dataset, 0.4, 0.2, 0.2, 0.2)\n",
    "    graph = prepocessing(dataset)\n",
    "    if test(graph):\n",
    "        print(\"Undirected!\")\n",
    "    else:\n",
    "        print('Directed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(809, device='cuda:4')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(G.edge_pseudolabel[G.test_index]>=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1901, device='cuda:4')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(G.test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2534, device='cuda:4')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(G.edge_pseudolabel[indices]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(695, device='cuda:4')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(G.edge_pseudolabel[indices]==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6993, device='cuda:4')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean((G.y[indices] == G.edge_pseudolabel[indices])*1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([1,2,3,4,5])\n",
    "k=A[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "k[1] = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 9, 3, 4, 5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False,  True])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "A = torch.tensor([[True, False],[False,True],[True,True]]).T\n",
    "torch.logical_and(A[0,:], A[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[0,1],[0,2]]).T\n",
    "labels = torch.tensor([1,2,3])\n",
    "torch.cat((labels[A[0,:]].unsqueeze(0), labels[A[1,:]].unsqueeze(0)), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 2]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 2]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(A, dim=1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  6],\n",
       "       [14, 14]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(A) @ np.array(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Non_Homophily_Large_Scale.dataset import *\n",
    "\n",
    "# datanames = ['twitch-e', 'fb100', 'ogbn-proteins', 'deezer-europe', 'arxiv-year', 'pokec', 'snap-patents',\n",
    "#              'yelp-chi', 'ogbn-arxiv', 'ogbn-products', 'Cora', 'CiteSeer', 'PubMed', 'chameleon', 'cornell',\n",
    "#              'film', 'squirrel', 'texas', 'wisconsin', 'genius', 'twitch-gamer', 'wiki']\n",
    "datanames = ['yelp-chi']\n",
    "\n",
    "for data in datanames:\n",
    "    dataset = load_nc_dataset(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "np.save('ss.npy', np.array([12,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "# def random_select(tensor, K):\n",
    "tensor = torch.zeros(10)\n",
    "K = 5\n",
    "indices = random.sample(range(10), K)  # 从 0 到 N-1 之间的索引中随机选择 K 个不重复的位置\n",
    "tensor.view(-1)[indices] = True  # 将选中位置的值设为 1\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tensor == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from utils import load_dataset, split_dataset\n",
    "from model import GCN\n",
    "datanames = ['twitch-e', 'fb100', 'ogbn-proteins', 'deezer-europe', 'arxiv-year', 'pokec', 'snap-patents',\n",
    "             'yelp-chi', 'ogbn-arxiv', 'ogbn-products', 'Cora', 'CiteSeer', 'PubMed', 'chameleon', 'cornell',\n",
    "             'film', 'squirrel', 'texas', 'wisconsin', 'genius', 'twitch-gamer', 'wiki']\n",
    "# datanames = ['fb100']\n",
    "\n",
    "# for data in datanames:\n",
    "#     dataset = load_dataset(data)\n",
    "#     print(data, len(dataset))\n",
    "data = 'yelp-chi'\n",
    "dataset = load_dataset(data)\n",
    "split_dataset(dataset, 0.2, 0.8)\n",
    "\n",
    "graph = dataset[0][0]\n",
    "label = dataset.label\n",
    "num_class = len(torch.unique(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for key in graph.keys():\n",
    "    print(key=='node_feat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7417, -0.4761],\n",
       "        [ 0.1925, -0.0169],\n",
       "        [ 0.2426,  0.0991],\n",
       "        [ 0.1326,  0.4701],\n",
       "        [ 1.0000, -0.5986],\n",
       "        [ 0.3264,  0.3041]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn((6,2))\n",
    "A = A / A.max()\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, index = A.max(dim=1)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = Data(x=graph['node_feat'])\n",
    "'pes' in G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.max(torch.tensor(10), torch.tensor(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:15<03:22,  2.18s/iteration]\n",
      " 22%|██▏       | 22/100 [00:07<00:24,  3.14iteration/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m progress_bar\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m      8\u001b[0m k \u001b[39m=\u001b[39m k\u001b[39m+\u001b[39mtorch\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m,\u001b[39m5\u001b[39m,(\u001b[39m1\u001b[39m,))\u001b[39m.\u001b[39mitem()\n\u001b[0;32m----> 9\u001b[0m time\u001b[39m.\u001b[39;49msleep(\u001b[39m1\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "progress_bar = tqdm(total=100, unit='iteration')\n",
    "import time \n",
    "k = 0\n",
    "while k<100:\n",
    "    progress_bar.n = k\n",
    "    progress_bar.refresh()\n",
    "    k = k+torch.randint(0,5,(1,)).item()\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.7500)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 模型预测值\n",
    "predictions = torch.tensor([[0.1, 0.2, 0.7], [0.8, 0.1, 0.1]])\n",
    "\n",
    "# 真实标签\n",
    "targets = torch.tensor([2, 0])\n",
    "\n",
    "# 计算负对数似然损失\n",
    "loss = F.nll_loss(predictions, targets)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [1],\n",
      "        [0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设有一个N*2的概率张量\n",
    "probabilities = torch.tensor([[0, 1], [0.6, 0.4], [0.3, 0.7]])\n",
    "\n",
    "# 对概率张量进行采样\n",
    "samples = torch.multinomial(probabilities, 1, replacement=True)\n",
    "\n",
    "# 打印采样结果\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5590,  0.0183],\n",
      "        [ 0.2898, -0.6151],\n",
      "        [ 0.5590,  0.0183]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "N, m, k = 3, 4, 2  # 假设的维度\n",
    "\n",
    "# 假设有一个N*m维的张量X\n",
    "X = torch.randn(N, m)\n",
    "\n",
    "# 假设有一个N维的张量P\n",
    "P = torch.tensor([0, 1, 0])\n",
    "\n",
    "# 假设有一组MLP\n",
    "mlps = nn.ModuleList([nn.Linear(m, k) for _ in range(N)])\n",
    "\n",
    "# 将每一行的X通过对应的MLP进行前向传播\n",
    "X_prime = torch.stack([mlps[i](X[i]) for i in P])\n",
    "\n",
    "print(X_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "A = torch.randn((3,2))\n",
    "A[1] = torch.tensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 假设你的张量名为 tensor\n",
    "tensor = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6],\n",
    "                       [1, 2, 3],\n",
    "                       [7, 8, 9],\n",
    "                       [4, 5, 6]])\n",
    "\n",
    "# 使用 torch.unique 函数找到唯一的张量和索引\n",
    "unique_tensor, inverse_indices = torch.unique(tensor, dim=0, return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame()\n",
    "dic = df.to_dict()\n",
    "dic['fb100'] = {}\n",
    "dic['fb100']['GCN'] = 1\n",
    "df = pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid sub_dataname, deferring to Penn94 graph\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'computational_graph.pdf'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot\n",
    "from model import GCN\n",
    "from utils import load_dataset,prepocessing\n",
    "\n",
    "data = load_dataset('fb100')\n",
    "graph = prepocessing(data)\n",
    "# 创建模型实例\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "model = GCN(4814,32,2, num_layers=3, dropout=0.3)\n",
    "model.eval()\n",
    "\n",
    "# 前向传播获取输出\n",
    "outputs = model(graph)\n",
    "\n",
    "# 可视化计算图\n",
    "make_dot(outputs, params=dict(model.named_parameters())).render(\"computational_graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([3, 2, 3, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter('baabbcccs').values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected indices: tensor([4, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 示例tensor和batch大小\n",
    "my_tensor = torch.tensor([False, True, False, True, True])\n",
    "batch_size = 2\n",
    "\n",
    "# 找到所有为True的索引\n",
    "true_indices = torch.where(my_tensor)[0]\n",
    "\n",
    "# 如果True的数量少于batch大小，取所有True；否则随机抽样\n",
    "if len(true_indices) <= batch_size:\n",
    "    selected_indices = true_indices\n",
    "else:\n",
    "    shuffled_indices = torch.randperm(len(true_indices))[:batch_size]\n",
    "    selected_indices = true_indices[shuffled_indices]\n",
    "\n",
    "# 输出结果\n",
    "print(\"Selected indices:\", selected_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tensor = torch.tensor([False, True, False, True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = my_tensor.clone()\n",
    "A[selected_indices] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# 创建节点特征矩阵\n",
    "x = torch.tensor([[1, 2], [3, 4], [5, 6]], dtype=torch.float)\n",
    "\n",
    "# 创建边索引矩阵\n",
    "edge_index = torch.tensor([[0, 1, 1, 2,3], [1, 0, 2, 1,4]], dtype=torch.long)\n",
    "\n",
    "# 创建边特征矩阵（可选）\n",
    "edge_attr = torch.tensor([[0.5], [1.0], [2.0], [1.5]], dtype=torch.float)\n",
    "\n",
    "# 创建类别标签（可选）\n",
    "y = torch.tensor([0, 1, 1], dtype=torch.long)\n",
    "\n",
    "# 创建权重（可选）\n",
    "weight = torch.tensor([0.1, 0.2, 0.3, 0.4], dtype=torch.float)\n",
    "\n",
    "# 创建一个 Data 对象\n",
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y, weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def find_edges_connected_to_nodes(data, node_indices):\n",
    "\n",
    "    node_indices = torch.tensor(node_indices)\n",
    "    mask = (data.edge_index[0].unsqueeze(1) == node_indices) | (data.edge_index[1].unsqueeze(1) == node_indices)\n",
    "    mask = mask.any(dim=1)\n",
    "    edge_indices = mask.nonzero(as_tuple=False).view(-1)\n",
    "    return edge_indices\n",
    "\n",
    "# 示例\n",
    "# 假设你的图数据对象是 `data`\n",
    "# 假设要找的节点索引列表是 `node_indices`\n",
    "node_indices = [0, 2]  # 你可以根据需要修改这个列表\n",
    "edge_indices = find_edges_connected_to_nodes(data, node_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "edge_indices = torch.tensor([0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "A = torch.randn((3,2))\n",
    "B = torch.randn((3,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.1151)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = 0\n",
    "torch.sum((A-B) * (A-B))/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([2,3,1,5,4])\n",
    "B = torch.tensor([[1,1],\n",
    "                  [2,2],\n",
    "                  [3,3],\n",
    "                  [4,4],\n",
    "                  [5,5]], dtype=float)\n",
    "sorted_indices = torch.argsort(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_sorted = B[sorted_indices]\n",
    "tmp = B_sorted[:2]\n",
    "C = [torch.zeros_like(B_sorted[:2]), B_sorted[2:]*0.7]\n",
    "\n",
    "C = torch.cat(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000],\n",
       "        [1.4000, 1.4000],\n",
       "        [0.0000, 0.0000],\n",
       "        [2.8000, 2.8000],\n",
       "        [3.5000, 3.5000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.argsort(sorted_indices)\n",
    "C = C[indices]\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid sub_dataname, deferring to DE graph\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from train import *\n",
    "\n",
    "seed = 42\n",
    "dataset = load_dataset('twitch-e')\n",
    "split_dataset(dataset, 0.8, 0.1, 0.1)\n",
    "graph = prepocessing(dataset)\n",
    "\n",
    "\n",
    "graph.to('cuda:4')\n",
    "\n",
    "graph.pseudolabel = torch.zeros_like(graph.y)-2 # '-2' means labeled data\n",
    "graph.pseudolabel[graph['test_index']] = -1 # '-1' means unlabeled data\n",
    "if 'val_index' in graph:\n",
    "    graph.pseudolabel[graph['val_index']] = -1 # validation data is treated equally as unlabeled data\n",
    "\n",
    "graph.training_labels = graph.pseudolabel.clone()\n",
    "graph.training_labels[graph['train_index']] = graph.y[graph['train_index']]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:0.8136620280146599, Std:0.08369003941252974\n"
     ]
    }
   ],
   "source": [
    "loss_1 = []\n",
    "for _ in range(1000):\n",
    "    model = ourModel(input_dim=graph.num_features, \n",
    "                output_dim=graph.num_class, \n",
    "                hidden_dim=32, \n",
    "                num_layers=3,\n",
    "                dropout=0.3)\n",
    "    model.to('cuda:4')\n",
    "    logits = model(graph)\n",
    "    loss_1.append(criterion(logits[graph['test_index']], graph.y[graph['test_index']]).item())\n",
    "\n",
    "import numpy as np \n",
    "print(f'Mean:{np.mean(loss_1)}, Std:{np.std(loss_1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:0.8580606465041637, Std:0.07528020457664462\n"
     ]
    }
   ],
   "source": [
    "loss_2 = []\n",
    "model = ourModel(input_dim=graph.num_features, \n",
    "            output_dim=graph.num_class, \n",
    "            hidden_dim=32, \n",
    "            num_layers=3,\n",
    "            dropout=0.3)\n",
    "for _ in range(1000):\n",
    "    model.restart()\n",
    "    model.to('cuda:4')\n",
    "    logits = model(graph)\n",
    "    loss_1.append(criterion(logits[graph['test_index']], graph.y[graph['test_index']]).item())\n",
    "\n",
    "print(f'Mean:{np.mean(loss_1)}, Std:{np.std(loss_1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3,4,5])[torch.tensor([False,False,False,True,False])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.zeros(3).cuda()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(x.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "k = torch.tensor([[0.1,0.9],[0.2,0.8]])\n",
    "pred = torch.argmax(torch.tensor([[0.1,0.9],[0.2,0.8]]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.9000, 0.8000]),\n",
       "indices=tensor([1, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(k, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ourModel\n",
    "from copy import deepcopy \n",
    "import torch\n",
    "model = ourModel(1205,32,2,3,0.3)\n",
    "model_a = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_a = model_a.convs[0].lin.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = model.convs[0].lin.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.convs[0].lin.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.requires_grad = False\n",
    "model.convs[0].lin.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m5\u001b[39m\u001b[39m<\u001b[39m\u001b[39m4\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 5<4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\torchaudio\\backend\\utils.py:62: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'timm.models.layers.helpers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Life\\Study\\科研\\Graph_Pseudo_Label\\Graph_pseudo_labeling\\grinding_workshop.ipynb 单元格 46\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Life/Study/%E7%A7%91%E7%A0%94/Graph_Pseudo_Label/Graph_pseudo_labeling/grinding_workshop.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msemilearn\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Life/Study/%E7%A7%91%E7%A0%94/Graph_Pseudo_Label/Graph_pseudo_labeling/grinding_workshop.ipynb#X63sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msemilearn\u001b[39;00m \u001b[39mimport\u001b[39;00m get_dataset, get_data_loader, get_net_builder, get_algorithm, get_config, Trainer\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\__init__.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright (c) Microsoft Corporation.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Licensed under the MIT License.\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlighting\u001b[39;00m \u001b[39mimport\u001b[39;00m Trainer, get_config\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_dataset, get_data_loader, get_net_builder\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39malgorithms\u001b[39;00m \u001b[39mimport\u001b[39;00m get_algorithm\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\lighting\\__init__.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright (c) Microsoft Corporation.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Licensed under the MIT License.\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtrainer\u001b[39;00m \u001b[39mimport\u001b[39;00m Trainer\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m get_config\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\lighting\\trainer.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mprogress\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbar\u001b[39;00m \u001b[39mimport\u001b[39;00m Bar\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\u001b[1;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msemilearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_optimizer, get_cosine_schedule_with_warmup, get_logger, EMA\n\u001b[0;32m     15\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mTrainer\u001b[39;00m:\n\u001b[0;32m     16\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, config, algorithm, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\core\\__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39malgorithmbase\u001b[39;00m \u001b[39mimport\u001b[39;00m AlgorithmBase, ImbAlgorithmBase\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\core\\algorithmbase.py:15\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcuda\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mamp\u001b[39;00m \u001b[39mimport\u001b[39;00m autocast, GradScaler\n\u001b[1;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msemilearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhooks\u001b[39;00m \u001b[39mimport\u001b[39;00m Hook, get_priority, CheckpointHook, TimerHook, LoggingHook, DistSamplerSeedHook, ParamUpdateHook, EvaluationHook, EMAHook\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msemilearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_dataset, get_data_loader, get_optimizer, get_cosine_schedule_with_warmup, Bn_Controller\n\u001b[0;32m     19\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mAlgorithmBase\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\core\\hooks\\__init__.py:12\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39msampler_seed\u001b[39;00m \u001b[39mimport\u001b[39;00m DistSamplerSeedHook\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtimer\u001b[39;00m \u001b[39mimport\u001b[39;00m TimerHook\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mema\u001b[39;00m \u001b[39mimport\u001b[39;00m EMAHook\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\core\\hooks\\ema.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright (c) Microsoft Corporation.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Licensed under the MIT License.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mhook\u001b[39;00m \u001b[39mimport\u001b[39;00m Hook\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msemilearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m EMA\n\u001b[0;32m      9\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mEMAHook\u001b[39;00m(Hook):\n\u001b[0;32m     10\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\core\\utils\\__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbuild\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmisc\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\core\\utils\\build.py:12\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msemilearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_collactor, name2sampler\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msemilearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m param_groups_layer_decay, param_groups_weight_decay\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_net_builder\u001b[39m(net_name, from_name: \u001b[39mbool\u001b[39m):\n\u001b[0;32m     15\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m    built network according to network name\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m    return **class** of backbone network (not instance).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39m        from_name: If True, net_buidler takes models in torch.vision models. Then, net_conf is ignored.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\nets\\__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresnet\u001b[39;00m \u001b[39mimport\u001b[39;00m resnet50\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mwrn\u001b[39;00m \u001b[39mimport\u001b[39;00m wrn_28_2, wrn_28_8, wrn_var_37_2\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvit\u001b[39;00m \u001b[39mimport\u001b[39;00m vit_base_patch16_224, vit_small_patch16_224, vit_small_patch2_32, vit_tiny_patch2_32, vit_base_patch16_96\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbert\u001b[39;00m \u001b[39mimport\u001b[39;00m bert_base_cased, bert_base_uncased\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mwave2vecv2\u001b[39;00m \u001b[39mimport\u001b[39;00m wave2vecv2_base\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\nets\\vit\\__init__.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright (c) Microsoft Corporation.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Licensed under the MIT License.\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvit\u001b[39;00m \u001b[39mimport\u001b[39;00m vit_tiny_patch2_32, vit_small_patch2_32, vit_small_patch16_224, vit_base_patch16_224, vit_base_patch16_96\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvit\u001b[39;00m \u001b[39mimport\u001b[39;00m VisionTransformer\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\nets\\vit\\vit.py:13\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcheckpoint\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtimm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m DropPath, trunc_normal_\n\u001b[1;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtimm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhelpers\u001b[39;00m \u001b[39mimport\u001b[39;00m to_2tuple\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msemilearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m load_checkpoint\n\u001b[0;32m     18\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mPatchEmbed\u001b[39;00m(nn\u001b[39m.\u001b[39mModule):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'timm.models.layers.helpers'"
     ]
    }
   ],
   "source": [
    "import semilearn\n",
    "from semilearn import get_dataset, get_data_loader, get_net_builder, get_algorithm, get_config, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
