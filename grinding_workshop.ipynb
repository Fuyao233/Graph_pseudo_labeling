{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from basis_method.basis_process_dim32_class2 import *\n",
    "import torch \n",
    "\n",
    "basis_matrix = torch.tensor(basis_process_dim32_class2(h=0.5))\n",
    "torch.linalg.eigvals(torch.inverse(basis_matrix)).real.max(dim=2)[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.eigvals(torch.inverse(basis_matrix)).real.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6811990970>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from basis_method.basis_process_dim32_class2 import *\n",
    "import torch \n",
    "\n",
    "h = np.linspace(0.01, 0.2, 30)\n",
    "res_dic = {\n",
    "    'h': [],\n",
    "    'seed': [],\n",
    "    'max': [],\n",
    "    'max_inv': []\n",
    "}\n",
    "\n",
    "for test_h in h:\n",
    "    for _ in range(10):\n",
    "        seed = np.random.randint(100)\n",
    "        basis_matrix = basis_process_dim32_class2(h=test_h, seed=seed)\n",
    "        basis_matrix = torch.tensor(basis_matrix)\n",
    "        inv = torch.inverse(basis_matrix)\n",
    "        res_dic['h'].append(test_h)\n",
    "        res_dic['seed'].append(seed)\n",
    "        res_dic['max'].append(basis_matrix.max().item())\n",
    "        res_dic['max_inv'].append(inv.max().item())\n",
    "        \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "max_inv = []\n",
    "df = pd.DataFrame(res_dic)\n",
    "\n",
    "for t_h in h:\n",
    "    max_inv.append(df['max_inv'][df['h']==t_h].mean())\n",
    "\n",
    "plt.plot(h, max_inv, '-o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290     9\n",
       "291    86\n",
       "292    18\n",
       "293    92\n",
       "294     9\n",
       "295    86\n",
       "296    18\n",
       "297    92\n",
       "298     9\n",
       "299    86\n",
       "Name: seed, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['seed'][df['h']==0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.0000e+00, -3.2001e-16, -4.0749e-16,  ..., -2.2204e-16,\n",
       "           -8.8818e-16, -8.8818e-16],\n",
       "          [-5.3631e-17,  1.0000e+00,  1.2806e-16,  ...,  1.1102e-15,\n",
       "           -1.7764e-15, -1.7764e-15],\n",
       "          [-1.6145e-16, -1.1555e-15,  1.0000e+00,  ..., -4.4409e-16,\n",
       "           -4.4409e-16, -4.4409e-16],\n",
       "          ...,\n",
       "          [ 4.0480e-15, -1.2960e-15, -8.1772e-16,  ...,  1.0000e+00,\n",
       "            0.0000e+00, -4.4409e-16],\n",
       "          [ 1.4765e-15, -3.1710e-15,  4.4359e-16,  ...,  1.5543e-15,\n",
       "            1.0000e+00, -1.7764e-15],\n",
       "          [ 1.1027e-15,  4.2369e-16,  6.1293e-16,  ..., -3.1086e-15,\n",
       "           -1.7764e-15,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00, -1.1653e-15, -7.1656e-17,  ...,  4.4409e-16,\n",
       "            3.5527e-15,  0.0000e+00],\n",
       "          [-1.1410e-15,  1.0000e+00,  1.9584e-15,  ..., -8.8818e-16,\n",
       "            0.0000e+00, -1.7764e-15],\n",
       "          [ 4.8726e-16, -5.8621e-16,  1.0000e+00,  ...,  8.8818e-16,\n",
       "            8.8818e-16, -4.4409e-16],\n",
       "          ...,\n",
       "          [-5.0897e-16,  2.3407e-16,  1.7044e-15,  ...,  1.0000e+00,\n",
       "            1.7764e-15,  1.3323e-15],\n",
       "          [-2.6943e-15,  2.0726e-15,  3.7983e-15,  ...,  0.0000e+00,\n",
       "            1.0000e+00, -4.4409e-16],\n",
       "          [ 9.2572e-16, -1.0094e-15,  3.8252e-15,  ...,  1.7764e-15,\n",
       "           -5.5511e-16,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00, -1.7928e-16, -3.4379e-15,  ...,  0.0000e+00,\n",
       "            0.0000e+00,  0.0000e+00],\n",
       "          [-4.9009e-15,  1.0000e+00, -1.0860e-15,  ..., -7.1054e-15,\n",
       "            4.2633e-14, -7.1054e-15],\n",
       "          [ 1.7088e-15,  1.6125e-14,  1.0000e+00,  ..., -1.1102e-15,\n",
       "            1.7764e-14,  1.9540e-14],\n",
       "          ...,\n",
       "          [-5.5356e-16,  1.2448e-14, -1.3959e-14,  ...,  1.0000e+00,\n",
       "           -1.4211e-14,  1.4211e-14],\n",
       "          [ 7.1844e-15,  1.3644e-14, -1.2407e-14,  ...,  0.0000e+00,\n",
       "            1.0000e+00,  4.4409e-15],\n",
       "          [-6.1521e-15,  1.8283e-14, -1.6455e-14,  ...,  1.5987e-14,\n",
       "            4.2633e-14,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00, -1.3504e-16,  2.0202e-16,  ...,  0.0000e+00,\n",
       "           -8.8818e-16,  4.4409e-16],\n",
       "          [-4.7164e-16,  1.0000e+00, -1.5414e-16,  ...,  3.8858e-15,\n",
       "           -6.6613e-16,  9.4369e-16],\n",
       "          [ 1.3685e-15, -8.2624e-17,  1.0000e+00,  ...,  1.2212e-15,\n",
       "            1.5266e-15, -8.3267e-16],\n",
       "          ...,\n",
       "          [-5.3087e-16,  2.4964e-16,  4.2095e-15,  ...,  1.0000e+00,\n",
       "            2.6507e-15, -2.2204e-16],\n",
       "          [ 6.5740e-16,  4.2829e-16, -1.7030e-15,  ...,  8.8818e-16,\n",
       "            1.0000e+00,  2.2204e-16],\n",
       "          [ 1.2773e-16,  8.7665e-16, -9.8604e-16,  ..., -2.2204e-15,\n",
       "            6.6613e-16,  1.0000e+00]]],\n",
       "\n",
       "\n",
       "        [[[ 1.0000e+00, -7.0558e-17,  6.2987e-17,  ...,  8.3267e-17,\n",
       "           -1.1796e-16,  0.0000e+00],\n",
       "          [ 4.6947e-17,  1.0000e+00, -2.2384e-17,  ...,  3.3307e-16,\n",
       "           -5.5511e-17,  0.0000e+00],\n",
       "          [-1.0680e-16,  8.7667e-17,  1.0000e+00,  ...,  1.9429e-16,\n",
       "           -5.5511e-17,  1.1102e-16],\n",
       "          ...,\n",
       "          [-6.0392e-16,  2.3570e-17, -4.7563e-17,  ...,  1.0000e+00,\n",
       "            2.9837e-16,  1.1102e-16],\n",
       "          [ 1.1181e-15,  6.9315e-17,  3.6374e-16,  ...,  1.6653e-16,\n",
       "            1.0000e+00, -1.7208e-15],\n",
       "          [ 3.7641e-17,  1.1170e-16, -2.3974e-17,  ..., -3.6776e-16,\n",
       "           -2.4980e-16,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00, -1.7917e-17,  6.0779e-17,  ...,  1.1102e-16,\n",
       "            1.3878e-16,  1.1102e-16],\n",
       "          [ 3.9586e-17,  1.0000e+00,  2.7905e-17,  ...,  1.1102e-16,\n",
       "            8.3267e-17, -2.2204e-16],\n",
       "          [ 1.4861e-16,  1.2306e-16,  1.0000e+00,  ...,  1.1102e-16,\n",
       "           -5.3776e-17, -1.1102e-16],\n",
       "          ...,\n",
       "          [ 3.1215e-16, -4.4528e-16, -1.6105e-16,  ...,  1.0000e+00,\n",
       "            2.2204e-16,  2.4980e-16],\n",
       "          [ 2.6383e-16, -4.4665e-16, -1.7333e-16,  ..., -1.6653e-16,\n",
       "            1.0000e+00, -3.3307e-16],\n",
       "          [-1.4980e-16, -7.5754e-18, -1.2873e-16,  ...,  5.5511e-17,\n",
       "           -9.7145e-17,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00, -1.2169e-16, -1.9776e-16,  ..., -1.1102e-16,\n",
       "           -1.1102e-16,  6.6613e-16],\n",
       "          [-2.4611e-16,  1.0000e+00,  5.7130e-17,  ...,  2.2204e-16,\n",
       "            6.3838e-16, -1.1102e-16],\n",
       "          [-4.9724e-16, -8.4714e-16,  1.0000e+00,  ...,  2.7756e-16,\n",
       "           -5.5511e-16, -3.3307e-16],\n",
       "          ...,\n",
       "          [-2.6831e-15,  2.0777e-15,  6.8699e-16,  ...,  1.0000e+00,\n",
       "            8.8818e-16, -8.8818e-16],\n",
       "          [ 1.1231e-15,  1.1260e-15, -7.7407e-16,  ...,  0.0000e+00,\n",
       "            1.0000e+00,  2.6645e-15],\n",
       "          [-6.8467e-16, -1.2943e-15,  6.8619e-16,  ..., -1.7764e-15,\n",
       "            8.8818e-16,  1.0000e+00]],\n",
       "\n",
       "         [[ 1.0000e+00, -2.8645e-17,  9.4546e-17,  ...,  0.0000e+00,\n",
       "           -5.5511e-17, -1.6653e-16],\n",
       "          [-3.1598e-16,  1.0000e+00, -3.7285e-17,  ..., -5.5511e-17,\n",
       "           -2.7756e-16,  0.0000e+00],\n",
       "          [ 2.0462e-16,  2.7933e-17,  1.0000e+00,  ..., -5.5511e-17,\n",
       "            0.0000e+00, -1.3184e-16],\n",
       "          ...,\n",
       "          [ 9.6660e-16,  1.5113e-16, -7.0895e-16,  ...,  1.0000e+00,\n",
       "            5.5511e-17,  4.4409e-16],\n",
       "          [-8.4967e-16, -2.2723e-16,  2.2740e-16,  ..., -2.7756e-16,\n",
       "            1.0000e+00,  1.3323e-15],\n",
       "          [-2.8114e-15, -3.0089e-16, -1.7421e-15,  ..., -4.4409e-16,\n",
       "            6.6613e-16,  1.0000e+00]]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis_matrix = basis_process_dim32_class2(h=10, seed=seed)\n",
    "basis_matrix = torch.tensor(basis_matrix)\n",
    "inv_basis_matrix = torch.inverse(basis_matrix)\n",
    "\n",
    "torch.einsum('ijkl, ijlp->ijkp', basis_matrix, inv_basis_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 32, 32])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis_matrix.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1])\n",
      "tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(A)\n",
    "a = a + 1\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "index_sequence.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "# 假设 tensor_a 和 tensor_b 是您的两个 4x8x8 张量\n",
    "tensor_a = torch.rand(4, 8, 8)\n",
    "tensor_b = torch.rand(4, 8, 8)\n",
    "\n",
    "# 使用 torch.einsum 进行运算\n",
    "result_einsum = torch.einsum('bij,bjk->bik', tensor_a, tensor_b)\n",
    "\n",
    "# 使用循环和 torch.matmul 进行逐个矩阵乘法\n",
    "result_loop = torch.stack([torch.matmul(tensor_a[i], tensor_b[i]) for i in range(tensor_a.size(0))])\n",
    "\n",
    "# 验证结果是否一致\n",
    "print(torch.allclose(result_einsum, result_loop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 1\n",
      "1 0\n",
      "1 1\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "for g in torch.cartesian_prod(torch.arange(2), torch.arange(2)).numpy():\n",
    "    print(g[0], g[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 5.],\n",
      "        [1., 3.],\n",
      "        [3., 6.],\n",
      "        [1., 3.]])\n"
     ]
    }
   ],
   "source": [
    "# scatter_mean 使用实例。特征从 edge_index[0] 传出，汇聚到 edge_index[1] 上\n",
    "\n",
    "import torch\n",
    "from torch_scatter import scatter_mean\n",
    "\n",
    "# 假设 x 是一个节点特征矩阵，大小为 [num_nodes, num_features]\n",
    "x = torch.tensor([[1, 3], [2, 4], [3, 5], [4, 8]], dtype=torch.float)\n",
    "\n",
    "# edge_index 定义了图的边，每一列代表一条边，行表示边的起点和终点\n",
    "edge_index = torch.tensor([[0, 1, 2, 0, 3], [1, 2, 0, 3, 2]], dtype=torch.long)\n",
    "\n",
    "# 使用 edge_index 的第一行来聚合特征，因为它代表目标节点的索引\n",
    "target = edge_index[1]\n",
    "\n",
    "# 执行 scatter_mean 来聚合特征\n",
    "# x[edge_index[0]] 将源节点的特征提取出来\n",
    "# target 定义了应该聚合到哪个节点上\n",
    "# dim_size 是目标节点的数量\n",
    "node_feature_aggregated = scatter_mean(x[edge_index[0]], target, dim=0, dim_size=x.size(0))\n",
    "\n",
    "print(node_feature_aggregated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 2, 2, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 2, 2, 3, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "# 下标索引生成的张量与之前的张量元素相互独立\n",
    "A = torch.tensor([1,2,3])\n",
    "B = A[[0,0,1,1,2,2]]\n",
    "print(B)\n",
    "A[0] = 9\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp-chi\n",
      "Undirected!\n",
      "deezer-europe\n",
      "Undirected!\n",
      "pokec\n",
      "Undirected!\n",
      "arxiv-year\n",
      "Undirected!\n",
      "snap-patents\n",
      "Undirected!\n",
      "chameleon\n",
      "Undirected!\n",
      "cornell\n",
      "Undirected!\n",
      "squirrel\n",
      "Undirected!\n",
      "texas\n",
      "Undirected!\n",
      "wisconsin\n",
      "Undirected!\n"
     ]
    }
   ],
   "source": [
    "# 读取 utiles_data 中的数据\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from utils import load_dataset\n",
    "from model import GCN, ourModel, MLP\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "import torch.nn.functional as F\n",
    "from selecting_algorithm import Flexmatch, UPS\n",
    "import os \n",
    "import pandas as pd \n",
    "import argparse\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import yaml\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "def test(graph):\n",
    "    for i in range(10):\n",
    "        if not torch.sum(graph.edge_index[0]==i) == torch.sum(graph.edge_index[0]==i):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "name_list = [\"yelp-chi\", \"deezer-europe\", \"pokec\", \"arxiv-year\", \"snap-patents\", \"chameleon\", \"cornell\", \"squirrel\", \"texas\", \"wisconsin\"]\n",
    "for name in name_list:\n",
    "    dataset = load_dataset(name)\n",
    "    print(name)\n",
    "    split_dataset_balanced(dataset, 0.4, 0.2, 0.2, 0.2)\n",
    "    graph = preprocessing(dataset)\n",
    "    if test(graph):\n",
    "        print(\"Undirected!\")\n",
    "    else:\n",
    "        print('Directed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(809, device='cuda:4')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(G.edge_pseudolabel[G.test_index]>=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1901, device='cuda:4')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(G.test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2534, device='cuda:4')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(G.edge_pseudolabel[indices]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(695, device='cuda:4')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(G.edge_pseudolabel[indices]==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6993, device='cuda:4')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean((G.y[indices] == G.edge_pseudolabel[indices])*1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([1,2,3,4,5])\n",
    "k=A[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "k[1] = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 9, 3, 4, 5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False,  True])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "A = torch.tensor([[True, False],[False,True],[True,True]]).T\n",
    "torch.logical_and(A[0,:], A[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[0,1],[0,2]]).T\n",
    "labels = torch.tensor([1,2,3])\n",
    "torch.cat((labels[A[0,:]].unsqueeze(0), labels[A[1,:]].unsqueeze(0)), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 2]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [1, 2]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(A, dim=1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  6],\n",
       "       [14, 14]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(A) @ np.array(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Non_Homophily_Large_Scale.dataset import *\n",
    "\n",
    "# datanames = ['twitch-e', 'fb100', 'ogbn-proteins', 'deezer-europe', 'arxiv-year', 'pokec', 'snap-patents',\n",
    "#              'yelp-chi', 'ogbn-arxiv', 'ogbn-products', 'Cora', 'CiteSeer', 'PubMed', 'chameleon', 'cornell',\n",
    "#              'film', 'squirrel', 'texas', 'wisconsin', 'genius', 'twitch-gamer', 'wiki']\n",
    "datanames = ['yelp-chi']\n",
    "\n",
    "for data in datanames:\n",
    "    dataset = load_nc_dataset(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "np.save('ss.npy', np.array([12,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "# def random_select(tensor, K):\n",
    "tensor = torch.zeros(10)\n",
    "K = 5\n",
    "indices = random.sample(range(10), K)  # 从 0 到 N-1 之间的索引中随机选择 K 个不重复的位置\n",
    "tensor.view(-1)[indices] = True  # 将选中位置的值设为 1\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tensor == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from utils import load_dataset, split_dataset\n",
    "from model import GCN\n",
    "datanames = ['twitch-e', 'fb100', 'ogbn-proteins', 'deezer-europe', 'arxiv-year', 'pokec', 'snap-patents',\n",
    "             'yelp-chi', 'ogbn-arxiv', 'ogbn-products', 'Cora', 'CiteSeer', 'PubMed', 'chameleon', 'cornell',\n",
    "             'film', 'squirrel', 'texas', 'wisconsin', 'genius', 'twitch-gamer', 'wiki']\n",
    "# datanames = ['fb100']\n",
    "\n",
    "# for data in datanames:\n",
    "#     dataset = load_dataset(data)\n",
    "#     print(data, len(dataset))\n",
    "data = 'yelp-chi'\n",
    "dataset = load_dataset(data)\n",
    "split_dataset(dataset, 0.2, 0.8)\n",
    "\n",
    "graph = dataset[0][0]\n",
    "label = dataset.label\n",
    "num_class = len(torch.unique(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for key in graph.keys():\n",
    "    print(key=='node_feat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7417, -0.4761],\n",
       "        [ 0.1925, -0.0169],\n",
       "        [ 0.2426,  0.0991],\n",
       "        [ 0.1326,  0.4701],\n",
       "        [ 1.0000, -0.5986],\n",
       "        [ 0.3264,  0.3041]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.randn((6,2))\n",
    "A = A / A.max()\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values, index = A.max(dim=1)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = Data(x=graph['node_feat'])\n",
    "'pes' in G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.max(torch.tensor(10), torch.tensor(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:15<03:22,  2.18s/iteration]\n",
      " 22%|██▏       | 22/100 [00:07<00:24,  3.14iteration/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m progress_bar\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m      8\u001b[0m k \u001b[39m=\u001b[39m k\u001b[39m+\u001b[39mtorch\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m,\u001b[39m5\u001b[39m,(\u001b[39m1\u001b[39m,))\u001b[39m.\u001b[39mitem()\n\u001b[0;32m----> 9\u001b[0m time\u001b[39m.\u001b[39;49msleep(\u001b[39m1\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "progress_bar = tqdm(total=100, unit='iteration')\n",
    "import time \n",
    "k = 0\n",
    "while k<100:\n",
    "    progress_bar.n = k\n",
    "    progress_bar.refresh()\n",
    "    k = k+torch.randint(0,5,(1,)).item()\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.7500)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 模型预测值\n",
    "predictions = torch.tensor([[0.1, 0.2, 0.7], [0.8, 0.1, 0.1]])\n",
    "\n",
    "# 真实标签\n",
    "targets = torch.tensor([2, 0])\n",
    "\n",
    "# 计算负对数似然损失\n",
    "loss = F.nll_loss(predictions, targets)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [1],\n",
      "        [0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设有一个N*2的概率张量\n",
    "probabilities = torch.tensor([[0, 1], [0.6, 0.4], [0.3, 0.7]])\n",
    "\n",
    "# 对概率张量进行采样\n",
    "samples = torch.multinomial(probabilities, 1, replacement=True)\n",
    "\n",
    "# 打印采样结果\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5590,  0.0183],\n",
      "        [ 0.2898, -0.6151],\n",
      "        [ 0.5590,  0.0183]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "N, m, k = 3, 4, 2  # 假设的维度\n",
    "\n",
    "# 假设有一个N*m维的张量X\n",
    "X = torch.randn(N, m)\n",
    "\n",
    "# 假设有一个N维的张量P\n",
    "P = torch.tensor([0, 1, 0])\n",
    "\n",
    "# 假设有一组MLP\n",
    "mlps = nn.ModuleList([nn.Linear(m, k) for _ in range(N)])\n",
    "\n",
    "# 将每一行的X通过对应的MLP进行前向传播\n",
    "X_prime = torch.stack([mlps[i](X[i]) for i in P])\n",
    "\n",
    "print(X_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "A = torch.randn((3,2))\n",
    "A[1] = torch.tensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 假设你的张量名为 tensor\n",
    "tensor = torch.tensor([[1, 2, 3],\n",
    "                       [4, 5, 6],\n",
    "                       [1, 2, 3],\n",
    "                       [7, 8, 9],\n",
    "                       [4, 5, 6]])\n",
    "\n",
    "# 使用 torch.unique 函数找到唯一的张量和索引\n",
    "unique_tensor, inverse_indices = torch.unique(tensor, dim=0, return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame()\n",
    "dic = df.to_dict()\n",
    "dic['fb100'] = {}\n",
    "dic['fb100']['GCN'] = 1\n",
    "df = pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid sub_dataname, deferring to Penn94 graph\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'computational_graph.pdf'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchviz import make_dot\n",
    "from model import GCN\n",
    "from utils import load_dataset,preprocessing\n",
    "\n",
    "data = load_dataset('fb100')\n",
    "graph = preprocessing(data)\n",
    "# 创建模型实例\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "model = GCN(4814,32,2, num_layers=3, dropout=0.3)\n",
    "model.eval()\n",
    "\n",
    "# 前向传播获取输出\n",
    "outputs = model(graph)\n",
    "\n",
    "# 可视化计算图\n",
    "make_dot(outputs, params=dict(model.named_parameters())).render(\"computational_graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([3, 2, 3, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter('baabbcccs').values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected indices: tensor([4, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 示例tensor和batch大小\n",
    "my_tensor = torch.tensor([False, True, False, True, True])\n",
    "batch_size = 2\n",
    "\n",
    "# 找到所有为True的索引\n",
    "true_indices = torch.where(my_tensor)[0]\n",
    "\n",
    "# 如果True的数量少于batch大小，取所有True；否则随机抽样\n",
    "if len(true_indices) <= batch_size:\n",
    "    selected_indices = true_indices\n",
    "else:\n",
    "    shuffled_indices = torch.randperm(len(true_indices))[:batch_size]\n",
    "    selected_indices = true_indices[shuffled_indices]\n",
    "\n",
    "# 输出结果\n",
    "print(\"Selected indices:\", selected_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tensor = torch.tensor([False, True, False, True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = my_tensor.clone()\n",
    "A[selected_indices] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# 创建节点特征矩阵\n",
    "x = torch.tensor([[1, 2], [3, 4], [5, 6]], dtype=torch.float)\n",
    "\n",
    "# 创建边索引矩阵\n",
    "edge_index = torch.tensor([[0, 1, 1, 2,3], [1, 0, 2, 1,4]], dtype=torch.long)\n",
    "\n",
    "# 创建边特征矩阵（可选）\n",
    "edge_attr = torch.tensor([[0.5], [1.0], [2.0], [1.5]], dtype=torch.float)\n",
    "\n",
    "# 创建类别标签（可选）\n",
    "y = torch.tensor([0, 1, 1], dtype=torch.long)\n",
    "\n",
    "# 创建权重（可选）\n",
    "weight = torch.tensor([0.1, 0.2, 0.3, 0.4], dtype=torch.float)\n",
    "\n",
    "# 创建一个 Data 对象\n",
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y, weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def find_edges_connected_to_nodes(data, node_indices):\n",
    "\n",
    "    node_indices = torch.tensor(node_indices)\n",
    "    mask = (data.edge_index[0].unsqueeze(1) == node_indices) | (data.edge_index[1].unsqueeze(1) == node_indices)\n",
    "    mask = mask.any(dim=1)\n",
    "    edge_indices = mask.nonzero(as_tuple=False).view(-1)\n",
    "    return edge_indices\n",
    "\n",
    "# 示例\n",
    "# 假设你的图数据对象是 `data`\n",
    "# 假设要找的节点索引列表是 `node_indices`\n",
    "node_indices = [0, 2]  # 你可以根据需要修改这个列表\n",
    "edge_indices = find_edges_connected_to_nodes(data, node_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "edge_indices = torch.tensor([0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "A = torch.randn((3,2))\n",
    "B = torch.randn((3,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.1151)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = 0\n",
    "torch.sum((A-B) * (A-B))/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([2,3,1,5,4])\n",
    "B = torch.tensor([[1,1],\n",
    "                  [2,2],\n",
    "                  [3,3],\n",
    "                  [4,4],\n",
    "                  [5,5]], dtype=float)\n",
    "sorted_indices = torch.argsort(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_sorted = B[sorted_indices]\n",
    "tmp = B_sorted[:2]\n",
    "C = [torch.zeros_like(B_sorted[:2]), B_sorted[2:]*0.7]\n",
    "\n",
    "C = torch.cat(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000],\n",
       "        [1.4000, 1.4000],\n",
       "        [0.0000, 0.0000],\n",
       "        [2.8000, 2.8000],\n",
       "        [3.5000, 3.5000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.argsort(sorted_indices)\n",
    "C = C[indices]\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid sub_dataname, deferring to DE graph\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from train import *\n",
    "\n",
    "seed = 42\n",
    "dataset = load_dataset('twitch-e')\n",
    "split_dataset(dataset, 0.8, 0.1, 0.1)\n",
    "graph = preprocessing(dataset)\n",
    "\n",
    "\n",
    "graph.to('cuda:4')\n",
    "\n",
    "graph.pseudolabel = torch.zeros_like(graph.y)-2 # '-2' means labeled data\n",
    "graph.pseudolabel[graph['test_index']] = -1 # '-1' means unlabeled data\n",
    "if 'val_index' in graph:\n",
    "    graph.pseudolabel[graph['val_index']] = -1 # validation data is treated equally as unlabeled data\n",
    "\n",
    "graph.training_labels = graph.pseudolabel.clone()\n",
    "graph.training_labels[graph['train_index']] = graph.y[graph['train_index']]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:0.8136620280146599, Std:0.08369003941252974\n"
     ]
    }
   ],
   "source": [
    "loss_1 = []\n",
    "for _ in range(1000):\n",
    "    model = ourModel(input_dim=graph.num_features, \n",
    "                output_dim=graph.num_class, \n",
    "                hidden_dim=32, \n",
    "                num_layers=3,\n",
    "                dropout=0.3)\n",
    "    model.to('cuda:4')\n",
    "    logits = model(graph)\n",
    "    loss_1.append(criterion(logits[graph['test_index']], graph.y[graph['test_index']]).item())\n",
    "\n",
    "import numpy as np \n",
    "print(f'Mean:{np.mean(loss_1)}, Std:{np.std(loss_1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:0.8580606465041637, Std:0.07528020457664462\n"
     ]
    }
   ],
   "source": [
    "loss_2 = []\n",
    "model = ourModel(input_dim=graph.num_features, \n",
    "            output_dim=graph.num_class, \n",
    "            hidden_dim=32, \n",
    "            num_layers=3,\n",
    "            dropout=0.3)\n",
    "for _ in range(1000):\n",
    "    model.restart()\n",
    "    model.to('cuda:4')\n",
    "    logits = model(graph)\n",
    "    loss_1.append(criterion(logits[graph['test_index']], graph.y[graph['test_index']]).item())\n",
    "\n",
    "print(f'Mean:{np.mean(loss_1)}, Std:{np.std(loss_1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1,2,3,4,5])[torch.tensor([False,False,False,True,False])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "x = torch.zeros(3).cuda()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(x.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "k = torch.tensor([[0.1,0.9],[0.2,0.8]])\n",
    "pred = torch.argmax(torch.tensor([[0.1,0.9],[0.2,0.8]]), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.9000, 0.8000]),\n",
       "indices=tensor([1, 1]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(k, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ourModel\n",
    "from copy import deepcopy \n",
    "import torch\n",
    "model = ourModel(1205,32,2,3,0.3)\n",
    "model_a = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_a = model_a.convs[0].lin.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = model.convs[0].lin.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.convs[0].lin.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.requires_grad = False\n",
    "model.convs[0].lin.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m5\u001b[39m\u001b[39m<\u001b[39m\u001b[39m4\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 5<4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\torchaudio\\backend\\utils.py:62: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'timm.models.layers.helpers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Life\\Study\\科研\\Graph_Pseudo_Label\\Graph_pseudo_labeling\\grinding_workshop.ipynb 单元格 46\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Life/Study/%E7%A7%91%E7%A0%94/Graph_Pseudo_Label/Graph_pseudo_labeling/grinding_workshop.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msemilearn\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Life/Study/%E7%A7%91%E7%A0%94/Graph_Pseudo_Label/Graph_pseudo_labeling/grinding_workshop.ipynb#X63sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msemilearn\u001b[39;00m \u001b[39mimport\u001b[39;00m get_dataset, get_data_loader, get_net_builder, get_algorithm, get_config, Trainer\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\__init__.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright (c) Microsoft Corporation.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Licensed under the MIT License.\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlighting\u001b[39;00m \u001b[39mimport\u001b[39;00m Trainer, get_config\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_dataset, get_data_loader, get_net_builder\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39malgorithms\u001b[39;00m \u001b[39mimport\u001b[39;00m get_algorithm\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\lighting\\__init__.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright (c) Microsoft Corporation.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Licensed under the MIT License.\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtrainer\u001b[39;00m \u001b[39mimport\u001b[39;00m Trainer\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m get_config\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\lighting\\trainer.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mprogress\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbar\u001b[39;00m \u001b[39mimport\u001b[39;00m Bar\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\u001b[1;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msemilearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_optimizer, get_cosine_schedule_with_warmup, get_logger, EMA\n\u001b[0;32m     15\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mTrainer\u001b[39;00m:\n\u001b[0;32m     16\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, config, algorithm, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\core\\__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39malgorithmbase\u001b[39;00m \u001b[39mimport\u001b[39;00m AlgorithmBase, ImbAlgorithmBase\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\core\\algorithmbase.py:15\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mF\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcuda\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mamp\u001b[39;00m \u001b[39mimport\u001b[39;00m autocast, GradScaler\n\u001b[1;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msemilearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhooks\u001b[39;00m \u001b[39mimport\u001b[39;00m Hook, get_priority, CheckpointHook, TimerHook, LoggingHook, DistSamplerSeedHook, ParamUpdateHook, EvaluationHook, EMAHook\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msemilearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_dataset, get_data_loader, get_optimizer, get_cosine_schedule_with_warmup, Bn_Controller\n\u001b[0;32m     19\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mAlgorithmBase\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\core\\hooks\\__init__.py:12\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39msampler_seed\u001b[39;00m \u001b[39mimport\u001b[39;00m DistSamplerSeedHook\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtimer\u001b[39;00m \u001b[39mimport\u001b[39;00m TimerHook\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mema\u001b[39;00m \u001b[39mimport\u001b[39;00m EMAHook\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\core\\hooks\\ema.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright (c) Microsoft Corporation.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Licensed under the MIT License.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mhook\u001b[39;00m \u001b[39mimport\u001b[39;00m Hook\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msemilearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m EMA\n\u001b[0;32m      9\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mEMAHook\u001b[39;00m(Hook):\n\u001b[0;32m     10\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\core\\utils\\__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbuild\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmisc\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\core\\utils\\build.py:12\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msemilearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_collactor, name2sampler\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msemilearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m param_groups_layer_decay, param_groups_weight_decay\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_net_builder\u001b[39m(net_name, from_name: \u001b[39mbool\u001b[39m):\n\u001b[0;32m     15\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m    built network according to network name\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m    return **class** of backbone network (not instance).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39m        from_name: If True, net_buidler takes models in torch.vision models. Then, net_conf is ignored.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\nets\\__init__.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresnet\u001b[39;00m \u001b[39mimport\u001b[39;00m resnet50\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mwrn\u001b[39;00m \u001b[39mimport\u001b[39;00m wrn_28_2, wrn_28_8, wrn_var_37_2\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvit\u001b[39;00m \u001b[39mimport\u001b[39;00m vit_base_patch16_224, vit_small_patch16_224, vit_small_patch2_32, vit_tiny_patch2_32, vit_base_patch16_96\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbert\u001b[39;00m \u001b[39mimport\u001b[39;00m bert_base_cased, bert_base_uncased\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mwave2vecv2\u001b[39;00m \u001b[39mimport\u001b[39;00m wave2vecv2_base\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\nets\\vit\\__init__.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright (c) Microsoft Corporation.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# Licensed under the MIT License.\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvit\u001b[39;00m \u001b[39mimport\u001b[39;00m vit_tiny_patch2_32, vit_small_patch2_32, vit_small_patch16_224, vit_base_patch16_224, vit_base_patch16_96\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvit\u001b[39;00m \u001b[39mimport\u001b[39;00m VisionTransformer\n",
      "File \u001b[1;32md:\\Miniconda\\miniconda\\envs\\start\\lib\\site-packages\\semilearn\\nets\\vit\\vit.py:13\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcheckpoint\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtimm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m DropPath, trunc_normal_\n\u001b[1;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtimm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhelpers\u001b[39;00m \u001b[39mimport\u001b[39;00m to_2tuple\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msemilearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m load_checkpoint\n\u001b[0;32m     18\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mPatchEmbed\u001b[39;00m(nn\u001b[39m.\u001b[39mModule):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'timm.models.layers.helpers'"
     ]
    }
   ],
   "source": [
    "import semilearn\n",
    "from semilearn import get_dataset, get_data_loader, get_net_builder, get_algorithm, get_config, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph_exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
